{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ML4HC_Project01_Code:\n",
        "Part 2\n"
      ],
      "metadata": {
        "id": "dI4cIsxU8OVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import packages\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "5bD3QNX08Nx7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#install kaggle\n",
        "! pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi9URnvm7Ttr",
        "outputId": "5020bf58-65bf-40ee-bdab-b2f20b03c49e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLDVwwv87dqr",
        "outputId": "8c79b5c9-1140-465c-fcf2-f9021fd376e3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make tmp kaggle folder, add json, allow\n",
        "! mkdir ~/.kaggle\n",
        "! cp /content/drive/MyDrive/ETH/kaggle/kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dFNJyaz8Q4g",
        "outputId": "134c3a9d-f780-4e51-9c26-3f6db5075bb0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download and unzip dataset\n",
        "! kaggle datasets download paultimothymooney/chest-xray-pneumonia\n",
        "! unzip chest-xray-pneumonia.zip"
      ],
      "metadata": {
        "id": "3YHg8t7E4Wl1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1e5f62a-70a6-466e-ac33-d14ddaccb2ed"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chest-xray-pneumonia.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  chest-xray-pneumonia.zip\n",
            "replace chest_xray/__MACOSX/._chest_xray? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading dataset\n",
        "train = get_training_data('./chest_xray/train/')\n",
        "test = get_training_data('./chest_xray/test/')\n",
        "val = get_training_data('./chest_xray/val/')"
      ],
      "metadata": {
        "id": "R4RaxSFF49OO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "a075443b-650e-48ff-852e-83740659279b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'get_training_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-55472ecc14f4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# loading dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./chest_xray/train/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./chest_xray/test/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./chest_xray/val/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_training_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot examples\n",
        "plt.figure(figsize = (5,5))\n",
        "plt.imshow(train[0][0], cmap='gray')\n",
        "plt.title(labels[train[0][1]])\n",
        "\n",
        "plt.figure(figsize = (5,5))\n",
        "plt.imshow(train[-1][0], cmap='gray')\n",
        "plt.title(labels[train[-1][1]])"
      ],
      "metadata": {
        "id": "RAS7FBaj5A0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# descriptive stats"
      ],
      "metadata": {
        "id": "lAqC1Z925KDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ILVEK80Y-gOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize to [0,1]\n",
        "x_train = np.array(x_train) / 255\n",
        "x_val = np.array(x_val) / 255\n",
        "x_test = np.array(x_test) / 255"
      ],
      "metadata": {
        "id": "AZqAWSU9-gJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resize data for deep learning\n",
        "x_train = x_train.reshape(-1, img_size, img_size, 1)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "x_val = x_val.reshape(-1, img_size, img_size, 1)\n",
        "y_val = np.array(y_val)\n",
        "\n",
        "x_test = x_test.reshape(-1, img_size, img_size, 1)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "IFmKEjdP-gGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define CNN\n",
        "net = nn.Sequential(\n",
        "  nn.Flatten(),\n",
        "  nn.Linear(784, 10), # 784 inputs, 10 outputs\n",
        "  nn.LogSoftmax(dim=1)\n",
        ")\n"
      ],
      "metadata": {
        "id": "lEfYy5OQ-gCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "net = net.to(device)"
      ],
      "metadata": {
        "id": "W-Ul9X9M-f4H"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batching\n",
        "train_loader = torch.utils.data.DataLoader(data_train, batch_size=64)\n",
        "test_loader = torch.utils.data.DataLoader(data_test, batch_size=64)"
      ],
      "metadata": {
        "id": "CEIh0jtW5Llg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(net, dataloader, device, lr=0.01, optimiser=None, loss_fn = nn.NLLLoss()):\n",
        "    optimiser = optimiser or torch.optim.Adam(net.parameters(), lr=lr)\n",
        "    # Ensure the network is in training mode\n",
        "    net.train()\n",
        "    total_loss, acc, count = 0,0,0\n",
        "    for features,labels in dataloader:\n",
        "        # Ensure features/images and labels are on the correct device\n",
        "        features, labels = features.to(device), labels.to(device)\n",
        "        # Predict outputs for features and compute the loss between predictions\n",
        "        # and labels\n",
        "        out = net(features)\n",
        "        loss = loss_fn(out, labels)\n",
        "        total_loss += loss\n",
        "\n",
        "        # Zero gradients from earlier computations\n",
        "        optimiser.zero_grad()\n",
        "        # Compute gradients for weights\n",
        "        loss.backward()\n",
        "        # Do optimiser step\n",
        "        optimiser.step()\n",
        "\n",
        "        # Get predicted classes as the entry with the highest probability\n",
        "        _, predicted = torch.max(out, 1)\n",
        "        # Compute accuracy\n",
        "        acc += (predicted == labels).sum().cpu()\n",
        "        count += len(labels)\n",
        "    return total_loss.item()/count, acc.item()/count\n",
        "\n",
        "train_epoch(net, train_loader, device)"
      ],
      "metadata": {
        "id": "XPGoWNq9E1QT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_epoch(net, dataloader, device, loss_fn=nn.NLLLoss()):\n",
        "    # Ensure network is in evaluation mode\n",
        "    net.eval()\n",
        "    count,acc,loss = 0,0,0\n",
        "    # We use torch.no_grad() to remove gradient computations\n",
        "    # This is not necessary, but can be much faster\n",
        "    with torch.no_grad():\n",
        "        for features,labels in dataloader:\n",
        "            # Ensure features and labels are on the correct device\n",
        "            features = features.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # Make predictions\n",
        "            out = net(features)\n",
        "            # Compute loss and accuracy of the model\n",
        "            loss += loss_fn(out,labels)\n",
        "            pred = torch.max(out,1)[1]\n",
        "            acc += (pred==labels).sum()\n",
        "            count += len(labels)\n",
        "    return loss.item()/count, acc.item()/count\n",
        "\n",
        "validate_epoch(net, test_loader, device)"
      ],
      "metadata": {
        "id": "1iOiyQCaFAXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overfitting?"
      ],
      "metadata": {
        "id": "ppMdzdI6FUx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#access overfitting\n",
        "def train(net, train_loader, test_loader, device=torch.device('cpu'), optimiser=None, lr=0.01, epochs=10, loss_fn=nn.NLLLoss()):\n",
        "    optimiser = optimiser or torch.optim.Adam(net.parameters(),lr=lr)\n",
        "    res = { 'train_loss' : [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "    for ep in range(epochs):\n",
        "        tl,ta = train_epoch(\n",
        "            net=net,\n",
        "            dataloader=train_loader,\n",
        "            device=device,\n",
        "            optimiser=optimiser, lr=lr, loss_fn=loss_fn)\n",
        "        vl,va = validate_epoch(\n",
        "            net=net,\n",
        "            dataloader=test_loader,\n",
        "            device=device,\n",
        "            loss_fn=loss_fn)\n",
        "        print(f\"Epoch {ep:2}, Train acc={ta:.3f}, Val acc={va:.3f}, Train loss={tl:.3f}, Val loss={vl:.3f}\")\n",
        "        res['train_loss'].append(tl)\n",
        "        res['train_acc'].append(ta)\n",
        "        res['val_loss'].append(vl)\n",
        "        res['val_acc'].append(va)\n",
        "    return res\n",
        "\n",
        "# Re-initialize the network to start from scratch\n",
        "net = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(784, 10),\n",
        "    nn.LogSoftmax(dim=1)\n",
        ").to(device)\n",
        "\n",
        "# This will take a minute or two\n",
        "hist = train(\n",
        "    net=net,\n",
        "    train_loader=train_loader,\n",
        "    test_loader=test_loader,\n",
        "    device=device,\n",
        "    epochs=10\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "w1-OevlIFBO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(121)\n",
        "plt.plot(hist['train_acc'], label='Training acc')\n",
        "plt.plot(hist['val_acc'], label='Validation acc')\n",
        "plt.legend()\n",
        "plt.subplot(122)\n",
        "plt.plot(hist['train_loss'], label='Training loss')\n",
        "plt.plot(hist['val_loss'], label='Validation loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "zxiEo4PMFTNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Integrated Gradients"
      ],
      "metadata": {
        "id": "f93r606XFXwH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cL2XNfceFa7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jkHW5D5GFbQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grad-CAM\n",
        "\n",
        "https://github.com/jacobgil/pytorch-grad-cam"
      ],
      "metadata": {
        "id": "7gkWI9UxFbsq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5W1TtkyQFdwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tF2TsFFQFeM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Randomization Test"
      ],
      "metadata": {
        "id": "a6npL0fcFgb1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hu01MHtEFhF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xx8L5ix1Fhai"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}